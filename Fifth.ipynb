{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.54)\n",
      "Requirement already satisfied: certifi in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (2.0.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\khong\\appdata\\roaming\\python\\python312\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\khong\\appdata\\roaming\\python\\python312\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\khong\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (4.55.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khong\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->roboflow) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khong\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->roboflow) (3.4.1)\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "# ===== Block 11 =====\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"iGSaRG2y43GaizViHQEx\")\n",
    "project = rf.workspace(\"machine-learning-class-eiri5\").project(\"intersection-traffic-piimy\")\n",
    "version = project.version(8)\n",
    "dataset = version.download(\"yolov8\")\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Block 2 =====\n",
    "# Imports for working with files, data processing, and model training\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch and torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# For visualizing embeddings\n",
    "from sklearn.manifold import TSNE\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Block 3 =====\n",
    "# Paths to the dataset\n",
    "dataset_path = \"C:\\\\ML_image_lab\\\\Intersection-Traffic--8\"\n",
    "output_path = \"C:\\\\ML_image_lab\\\\intersection_classification\"\n",
    "\n",
    "# Create directories for classification data\n",
    "categories = [\"bicycle\", \"bus\", \"car\", \"motorcycle\"]\n",
    "for category in categories:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(output_path, split, category), exist_ok=True)\n",
    "\n",
    "# Data preparation\n",
    "def prepare_classification_data(dataset_path, output_path, test_size=0.2, val_size=0.1):\n",
    "    image_paths = list(Path(dataset_path, \"train/images\").rglob(\"*.jpg\"))\n",
    "    labels_path = Path(dataset_path, \"train/labels\")\n",
    "\n",
    "    # Create (image, label) pairs\n",
    "    data = []\n",
    "    for image_path in image_paths:\n",
    "        label_path = labels_path / (image_path.stem + \".txt\")\n",
    "        if label_path.exists():\n",
    "            with label_path.open(\"r\") as f:\n",
    "                lines = [line.strip().split() for line in f]\n",
    "                if lines:\n",
    "                    # Take the first label as the class\n",
    "                    class_idx = int(lines[0][0])\n",
    "                    data.append((image_path, categories[class_idx]))\n",
    "\n",
    "    # Split into train, val, test\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=val_size, random_state=42)\n",
    "\n",
    "    # Copy data\n",
    "    def copy_data(split_data, split_name):\n",
    "        for image_path, category in split_data:\n",
    "            dest_path = Path(output_path, split_name, category, image_path.name)\n",
    "            shutil.copy(image_path, dest_path)\n",
    "\n",
    "    copy_data(train_data, \"train\")\n",
    "    copy_data(val_data, \"val\")\n",
    "    copy_data(test_data, \"test\")\n",
    "\n",
    "# Start data preparation\n",
    "prepare_classification_data(dataset_path, output_path)\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n",
      "Train Loss: 1.1430, Accuracy: 51.94%\n",
      "Val Loss: 0.9295, Accuracy: 55.86%\n",
      "Epoch [2/30]\n",
      "Train Loss: 0.9461, Accuracy: 55.41%\n",
      "Val Loss: 0.9172, Accuracy: 58.26%\n",
      "Epoch [3/30]\n",
      "Train Loss: 0.9022, Accuracy: 57.54%\n",
      "Val Loss: 0.8945, Accuracy: 57.92%\n",
      "Epoch [4/30]\n",
      "Train Loss: 0.8615, Accuracy: 59.66%\n",
      "Val Loss: 0.9228, Accuracy: 58.59%\n",
      "Epoch [5/30]\n",
      "Train Loss: 0.8194, Accuracy: 61.87%\n",
      "Val Loss: 0.8936, Accuracy: 58.06%\n",
      "Epoch [6/30]\n",
      "Train Loss: 0.7781, Accuracy: 64.04%\n",
      "Val Loss: 0.8951, Accuracy: 60.25%\n",
      "Epoch [7/30]\n",
      "Train Loss: 0.7293, Accuracy: 66.24%\n",
      "Val Loss: 0.8953, Accuracy: 60.45%\n",
      "Epoch [8/30]\n",
      "Train Loss: 0.6868, Accuracy: 68.32%\n",
      "Val Loss: 0.9350, Accuracy: 58.26%\n",
      "Epoch [9/30]\n",
      "Train Loss: 0.6375, Accuracy: 70.63%\n",
      "Val Loss: 0.9857, Accuracy: 58.12%\n",
      "Epoch [10/30]\n",
      "Train Loss: 0.5886, Accuracy: 72.97%\n",
      "Val Loss: 1.0613, Accuracy: 58.19%\n",
      "Epoch [11/30]\n",
      "Train Loss: 0.5660, Accuracy: 73.74%\n",
      "Val Loss: 1.0242, Accuracy: 57.46%\n",
      "Epoch [12/30]\n",
      "Train Loss: 0.5180, Accuracy: 75.89%\n",
      "Val Loss: 1.1210, Accuracy: 57.66%\n",
      "Epoch [13/30]\n",
      "Train Loss: 0.5033, Accuracy: 76.69%\n",
      "Val Loss: 1.2449, Accuracy: 58.46%\n",
      "Epoch [14/30]\n",
      "Train Loss: 0.4835, Accuracy: 77.35%\n",
      "Val Loss: 1.2036, Accuracy: 57.99%\n",
      "Epoch [15/30]\n",
      "Train Loss: 0.4608, Accuracy: 78.31%\n",
      "Val Loss: 1.2438, Accuracy: 59.12%\n",
      "Epoch [16/30]\n",
      "Train Loss: 0.4458, Accuracy: 78.71%\n",
      "Val Loss: 1.3046, Accuracy: 57.66%\n",
      "Epoch [17/30]\n",
      "Train Loss: 0.4251, Accuracy: 79.46%\n",
      "Val Loss: 1.4605, Accuracy: 58.59%\n",
      "Epoch [18/30]\n",
      "Train Loss: 0.4194, Accuracy: 79.86%\n",
      "Val Loss: 1.4662, Accuracy: 57.52%\n",
      "Epoch [19/30]\n",
      "Train Loss: 0.4115, Accuracy: 80.78%\n",
      "Val Loss: 1.3970, Accuracy: 58.26%\n",
      "Epoch [20/30]\n",
      "Train Loss: 0.3848, Accuracy: 81.13%\n",
      "Val Loss: 1.5167, Accuracy: 57.92%\n",
      "Epoch [21/30]\n",
      "Train Loss: 0.3887, Accuracy: 81.12%\n",
      "Val Loss: 1.4037, Accuracy: 57.26%\n",
      "Epoch [22/30]\n",
      "Train Loss: 0.3814, Accuracy: 81.49%\n",
      "Val Loss: 1.5199, Accuracy: 58.79%\n",
      "Epoch [23/30]\n",
      "Train Loss: 0.3769, Accuracy: 81.58%\n",
      "Val Loss: 1.6071, Accuracy: 58.06%\n",
      "Epoch [24/30]\n",
      "Train Loss: 0.3603, Accuracy: 82.15%\n",
      "Val Loss: 1.4477, Accuracy: 57.26%\n",
      "Epoch [25/30]\n",
      "Train Loss: 0.3470, Accuracy: 82.86%\n",
      "Val Loss: 1.7975, Accuracy: 58.26%\n",
      "Epoch [26/30]\n",
      "Train Loss: 0.3620, Accuracy: 82.82%\n",
      "Val Loss: 1.6055, Accuracy: 58.59%\n",
      "Epoch [27/30]\n",
      "Train Loss: 0.3368, Accuracy: 83.13%\n",
      "Val Loss: 1.8351, Accuracy: 58.59%\n",
      "Epoch [28/30]\n",
      "Train Loss: 0.3413, Accuracy: 82.94%\n",
      "Val Loss: 1.7465, Accuracy: 58.19%\n",
      "Epoch [29/30]\n",
      "Train Loss: 0.3393, Accuracy: 83.01%\n",
      "Val Loss: 1.8189, Accuracy: 57.86%\n",
      "Epoch [30/30]\n",
      "Train Loss: 0.3406, Accuracy: 83.23%\n",
      "Val Loss: 1.6851, Accuracy: 58.46%\n"
     ]
    }
   ],
   "source": [
    "# ===== Block 4 =====\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Data loading\n",
    "train_dataset = datasets.ImageFolder(root=f\"{output_path}/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{output_path}/val\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=f\"{output_path}/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.conv_layers(x)\n",
    "\n",
    "# Model initialization\n",
    "model = SimpleCNN(num_classes=len(categories)).to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    epoch_train_accs = []\n",
    "    epoch_val_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate average training loss and accuracy\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Calculate average validation loss and accuracy\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        # Store metrics for plotting\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "        epoch_val_losses.append(avg_val_loss)\n",
    "        epoch_train_accs.append(train_accuracy)\n",
    "        epoch_val_accs.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return epoch_train_losses, epoch_val_losses, epoch_train_accs, epoch_val_accs\n",
    "\n",
    "# Start training\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('CNN Model: Training and Validation Loss')\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Accuracy')\n",
    "plt.plot(val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('CNN Model: Training and Validation Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cnn_training_metrics.png\")\n",
    "plt.show()\n",
    "\n",
    "# Test the model on the test set\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    return avg_test_loss, test_accuracy\n",
    "\n",
    "# Evaluate on test set\n",
    "cnn_test_loss, cnn_test_acc = test_model(model, test_loader)\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Block 5 =====\n",
    "# Function to extract embeddings\n",
    "def extract_embeddings(model, loader, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Extract embeddings\n",
    "            features = model.conv_layers(images)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            embeddings.append(features.cpu().numpy())\n",
    "            labels.append(targets.cpu().numpy())\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return embeddings, labels\n",
    "\n",
    "# Extract embeddings\n",
    "train_embeddings, train_labels = extract_embeddings(model, train_loader, device)\n",
    "val_embeddings, val_labels = extract_embeddings(model, val_loader, device)\n",
    "\n",
    "# Visualization with TSNE\n",
    "def visualize_embeddings(embeddings, labels, title):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='viridis', s=5)\n",
    "    plt.colorbar(scatter, label=\"Class\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"TSNE Component 1\")\n",
    "    plt.ylabel(\"TSNE Component 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training embeddings\n",
    "visualize_embeddings(train_embeddings, train_labels, \"Train Embeddings (TSNE)\")\n",
    "\n",
    "# Visualize validation embeddings\n",
    "visualize_embeddings(val_embeddings, val_labels, \"Validation Embeddings (TSNE)\")\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\khong/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:05<00:00, 9.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n",
      "Train Loss: 0.9352, Accuracy: 55.62%\n",
      "Val Loss: 0.8913, Accuracy: 57.52%\n",
      "Epoch [2/30]\n",
      "Train Loss: 0.8889, Accuracy: 58.13%\n",
      "Val Loss: 0.8865, Accuracy: 57.26%\n",
      "Epoch [3/30]\n",
      "Train Loss: 0.8744, Accuracy: 58.67%\n",
      "Val Loss: 0.8764, Accuracy: 57.66%\n",
      "Epoch [4/30]\n",
      "Train Loss: 0.8638, Accuracy: 59.39%\n",
      "Val Loss: 0.8635, Accuracy: 59.45%\n",
      "Epoch [5/30]\n",
      "Train Loss: 0.8558, Accuracy: 59.63%\n",
      "Val Loss: 0.8691, Accuracy: 57.72%\n",
      "Epoch [6/30]\n",
      "Train Loss: 0.8530, Accuracy: 60.04%\n",
      "Val Loss: 0.8679, Accuracy: 58.92%\n",
      "Epoch [7/30]\n",
      "Train Loss: 0.8480, Accuracy: 59.94%\n",
      "Val Loss: 0.8634, Accuracy: 57.79%\n",
      "Epoch [8/30]\n",
      "Train Loss: 0.8401, Accuracy: 60.54%\n",
      "Val Loss: 0.8695, Accuracy: 57.99%\n",
      "Epoch [9/30]\n",
      "Train Loss: 0.8339, Accuracy: 60.59%\n",
      "Val Loss: 0.8540, Accuracy: 61.19%\n",
      "Epoch [10/30]\n",
      "Train Loss: 0.8286, Accuracy: 60.43%\n",
      "Val Loss: 0.8723, Accuracy: 59.39%\n",
      "Epoch [11/30]\n",
      "Train Loss: 0.8245, Accuracy: 60.89%\n",
      "Val Loss: 0.8686, Accuracy: 59.72%\n",
      "Epoch [12/30]\n",
      "Train Loss: 0.8206, Accuracy: 61.76%\n",
      "Val Loss: 0.8633, Accuracy: 59.52%\n",
      "Epoch [13/30]\n",
      "Train Loss: 0.8131, Accuracy: 62.15%\n",
      "Val Loss: 0.8689, Accuracy: 59.19%\n",
      "Epoch [14/30]\n",
      "Train Loss: 0.8158, Accuracy: 61.31%\n",
      "Val Loss: 0.8641, Accuracy: 60.12%\n",
      "Epoch [15/30]\n",
      "Train Loss: 0.8100, Accuracy: 61.65%\n",
      "Val Loss: 0.8658, Accuracy: 59.92%\n",
      "Epoch [16/30]\n",
      "Train Loss: 0.8023, Accuracy: 62.27%\n",
      "Val Loss: 0.8601, Accuracy: 60.85%\n",
      "Epoch [17/30]\n",
      "Train Loss: 0.7987, Accuracy: 62.06%\n",
      "Val Loss: 0.8772, Accuracy: 58.52%\n",
      "Epoch [18/30]\n",
      "Train Loss: 0.7981, Accuracy: 62.54%\n",
      "Val Loss: 0.8685, Accuracy: 58.26%\n",
      "Epoch [19/30]\n",
      "Train Loss: 0.7962, Accuracy: 62.22%\n",
      "Val Loss: 0.8979, Accuracy: 58.46%\n",
      "Epoch [20/30]\n",
      "Train Loss: 0.7895, Accuracy: 62.61%\n",
      "Val Loss: 0.8718, Accuracy: 59.72%\n",
      "Epoch [21/30]\n",
      "Train Loss: 0.7879, Accuracy: 62.75%\n",
      "Val Loss: 0.8733, Accuracy: 59.85%\n",
      "Epoch [22/30]\n",
      "Train Loss: 0.7836, Accuracy: 63.14%\n",
      "Val Loss: 0.8655, Accuracy: 59.59%\n",
      "Epoch [23/30]\n",
      "Train Loss: 0.7788, Accuracy: 62.78%\n",
      "Val Loss: 0.8803, Accuracy: 59.05%\n",
      "Epoch [24/30]\n",
      "Train Loss: 0.7749, Accuracy: 63.27%\n",
      "Val Loss: 0.8933, Accuracy: 59.52%\n",
      "Epoch [25/30]\n",
      "Train Loss: 0.7749, Accuracy: 63.75%\n",
      "Val Loss: 0.8738, Accuracy: 60.19%\n",
      "Epoch [26/30]\n",
      "Train Loss: 0.7747, Accuracy: 63.08%\n",
      "Val Loss: 0.8694, Accuracy: 59.25%\n",
      "Epoch [27/30]\n",
      "Train Loss: 0.7703, Accuracy: 63.45%\n",
      "Val Loss: 0.8943, Accuracy: 58.92%\n",
      "Epoch [28/30]\n",
      "Train Loss: 0.7734, Accuracy: 63.73%\n",
      "Val Loss: 0.8648, Accuracy: 58.26%\n",
      "Epoch [29/30]\n",
      "Train Loss: 0.7679, Accuracy: 62.98%\n",
      "Val Loss: 0.8786, Accuracy: 59.85%\n",
      "Epoch [30/30]\n",
      "Train Loss: 0.7591, Accuracy: 63.87%\n",
      "Val Loss: 0.8734, Accuracy: 58.52%\n"
     ]
    }
   ],
   "source": [
    "# ===== Block 6 =====\n",
    "# Load the pre-trained model\n",
    "pretrained_model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze backbone weights\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a custom classifier\n",
    "num_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, len(categories))\n",
    ")\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Optimizer and loss function for transfer learning\n",
    "criterion_tl = nn.CrossEntropyLoss()\n",
    "optimizer_tl = optim.Adam(pretrained_model.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize lists to store metrics for transfer learning\n",
    "tl_train_losses = []\n",
    "tl_val_losses = []\n",
    "tl_train_accs = []\n",
    "tl_val_accs = []\n",
    "\n",
    "# Train the model using Transfer Learning\n",
    "tl_train_losses, tl_val_losses, tl_train_accs, tl_val_accs = train_model(pretrained_model, train_loader, val_loader, criterion_tl, optimizer_tl, num_epochs)\n",
    "\n",
    "# Plot training and validation loss for transfer learning\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(tl_train_losses, label='Train Loss')\n",
    "plt.plot(tl_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('ResNet Transfer Learning: Training and Validation Loss')\n",
    "\n",
    "# Plot training and validation accuracy for transfer learning\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(tl_train_accs, label='Train Accuracy')\n",
    "plt.plot(tl_val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('ResNet Transfer Learning: Training and Validation Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"transfer_learning_metrics.png\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate transfer learning model on test set\n",
    "tl_test_loss, tl_test_acc = test_model(pretrained_model, test_loader)\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]\n",
      "Train Loss: 0.0810, Accuracy: 96.76%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [2/30]\n",
      "Train Loss: 0.0853, Accuracy: 96.72%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [3/30]\n",
      "Train Loss: 0.0826, Accuracy: 96.74%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [4/30]\n",
      "Train Loss: 0.0826, Accuracy: 96.64%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [5/30]\n",
      "Train Loss: 0.0802, Accuracy: 96.66%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [6/30]\n",
      "Train Loss: 0.0804, Accuracy: 96.84%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [7/30]\n",
      "Train Loss: 0.0835, Accuracy: 96.61%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [8/30]\n",
      "Train Loss: 0.0782, Accuracy: 96.71%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [9/30]\n",
      "Train Loss: 0.0864, Accuracy: 96.36%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [10/30]\n",
      "Train Loss: 0.0866, Accuracy: 96.57%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [11/30]\n",
      "Train Loss: 0.0827, Accuracy: 96.84%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [12/30]\n",
      "Train Loss: 0.0771, Accuracy: 96.80%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [13/30]\n",
      "Train Loss: 0.0812, Accuracy: 96.63%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [14/30]\n",
      "Train Loss: 0.0794, Accuracy: 96.84%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [15/30]\n",
      "Train Loss: 0.0826, Accuracy: 96.75%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [16/30]\n",
      "Train Loss: 0.0877, Accuracy: 96.49%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [17/30]\n",
      "Train Loss: 0.0807, Accuracy: 96.97%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [18/30]\n",
      "Train Loss: 0.0824, Accuracy: 96.86%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [19/30]\n",
      "Train Loss: 0.0809, Accuracy: 96.67%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [20/30]\n",
      "Train Loss: 0.0849, Accuracy: 96.69%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [21/30]\n",
      "Train Loss: 0.0793, Accuracy: 96.84%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [22/30]\n",
      "Train Loss: 0.0835, Accuracy: 96.77%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [23/30]\n",
      "Train Loss: 0.0794, Accuracy: 96.76%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [24/30]\n",
      "Train Loss: 0.0776, Accuracy: 96.96%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [25/30]\n",
      "Train Loss: 0.0829, Accuracy: 96.93%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [26/30]\n",
      "Train Loss: 0.0859, Accuracy: 96.60%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [27/30]\n",
      "Train Loss: 0.0861, Accuracy: 96.56%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [28/30]\n",
      "Train Loss: 0.0861, Accuracy: 96.60%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [29/30]\n",
      "Train Loss: 0.0831, Accuracy: 96.66%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [30/30]\n",
      "Train Loss: 0.0796, Accuracy: 96.77%\n",
      "Val Loss: 3.0345, Accuracy: 59.12%\n",
      "Epoch [1/30]\n",
      "Train Loss: 0.7589, Accuracy: 63.92%\n",
      "Val Loss: 0.8753, Accuracy: 59.19%\n",
      "Epoch [2/30]\n",
      "Train Loss: 0.7579, Accuracy: 64.01%\n",
      "Val Loss: 0.8901, Accuracy: 59.25%\n",
      "Epoch [3/30]\n",
      "Train Loss: 0.7603, Accuracy: 63.78%\n",
      "Val Loss: 0.8953, Accuracy: 58.19%\n",
      "Epoch [4/30]\n",
      "Train Loss: 0.7597, Accuracy: 63.77%\n",
      "Val Loss: 0.8880, Accuracy: 59.59%\n",
      "Epoch [5/30]\n",
      "Train Loss: 0.7532, Accuracy: 64.29%\n",
      "Val Loss: 0.9035, Accuracy: 60.65%\n",
      "Epoch [6/30]\n",
      "Train Loss: 0.7464, Accuracy: 64.54%\n",
      "Val Loss: 0.8826, Accuracy: 59.25%\n",
      "Epoch [7/30]\n",
      "Train Loss: 0.7465, Accuracy: 64.54%\n",
      "Val Loss: 0.8933, Accuracy: 59.05%\n",
      "Epoch [8/30]\n",
      "Train Loss: 0.7433, Accuracy: 64.48%\n",
      "Val Loss: 0.9259, Accuracy: 59.52%\n",
      "Epoch [9/30]\n",
      "Train Loss: 0.7404, Accuracy: 64.76%\n",
      "Val Loss: 0.8994, Accuracy: 59.52%\n",
      "Epoch [10/30]\n",
      "Train Loss: 0.7389, Accuracy: 65.29%\n",
      "Val Loss: 0.9195, Accuracy: 58.66%\n",
      "Epoch [11/30]\n",
      "Train Loss: 0.7393, Accuracy: 64.78%\n",
      "Val Loss: 0.8909, Accuracy: 59.59%\n",
      "Epoch [12/30]\n",
      "Train Loss: 0.7295, Accuracy: 64.80%\n",
      "Val Loss: 0.8931, Accuracy: 59.45%\n",
      "Epoch [13/30]\n",
      "Train Loss: 0.7311, Accuracy: 65.37%\n",
      "Val Loss: 0.9146, Accuracy: 59.39%\n",
      "Epoch [14/30]\n",
      "Train Loss: 0.7296, Accuracy: 65.21%\n",
      "Val Loss: 0.8933, Accuracy: 58.92%\n",
      "Epoch [15/30]\n",
      "Train Loss: 0.7258, Accuracy: 65.38%\n",
      "Val Loss: 0.9272, Accuracy: 59.65%\n",
      "Epoch [16/30]\n",
      "Train Loss: 0.7255, Accuracy: 65.85%\n",
      "Val Loss: 0.9183, Accuracy: 58.79%\n",
      "Epoch [17/30]\n",
      "Train Loss: 0.7270, Accuracy: 65.34%\n",
      "Val Loss: 0.9238, Accuracy: 58.46%\n",
      "Epoch [18/30]\n",
      "Train Loss: 0.7239, Accuracy: 66.04%\n",
      "Val Loss: 0.9163, Accuracy: 59.05%\n",
      "Epoch [19/30]\n",
      "Train Loss: 0.7244, Accuracy: 66.10%\n",
      "Val Loss: 0.9028, Accuracy: 59.32%\n",
      "Epoch [20/30]\n",
      "Train Loss: 0.7192, Accuracy: 66.11%\n",
      "Val Loss: 0.9111, Accuracy: 58.06%\n",
      "Epoch [21/30]\n",
      "Train Loss: 0.7185, Accuracy: 65.57%\n",
      "Val Loss: 0.9504, Accuracy: 58.12%\n",
      "Epoch [22/30]\n",
      "Train Loss: 0.7132, Accuracy: 66.19%\n",
      "Val Loss: 0.9227, Accuracy: 58.59%\n",
      "Epoch [23/30]\n",
      "Train Loss: 0.7153, Accuracy: 66.51%\n",
      "Val Loss: 0.9154, Accuracy: 57.79%\n",
      "Epoch [24/30]\n",
      "Train Loss: 0.7140, Accuracy: 66.11%\n",
      "Val Loss: 0.9455, Accuracy: 58.39%\n",
      "Epoch [25/30]\n",
      "Train Loss: 0.7135, Accuracy: 66.04%\n",
      "Val Loss: 0.9390, Accuracy: 58.26%\n",
      "Epoch [26/30]\n",
      "Train Loss: 0.7114, Accuracy: 65.95%\n",
      "Val Loss: 0.9276, Accuracy: 59.25%\n",
      "Epoch [27/30]\n",
      "Train Loss: 0.7079, Accuracy: 66.56%\n",
      "Val Loss: 0.9446, Accuracy: 58.59%\n",
      "Epoch [28/30]\n",
      "Train Loss: 0.7081, Accuracy: 66.25%\n",
      "Val Loss: 0.9401, Accuracy: 58.12%\n",
      "Epoch [29/30]\n",
      "Train Loss: 0.7077, Accuracy: 66.38%\n",
      "Val Loss: 0.9505, Accuracy: 57.92%\n",
      "Epoch [30/30]\n",
      "Train Loss: 0.7042, Accuracy: 66.63%\n",
      "Val Loss: 0.9596, Accuracy: 58.85%\n",
      "Simple CNN training time: 3636.58 seconds\n",
      "Transfer Learning training time: 3126.09 seconds\n"
     ]
    }
   ],
   "source": [
    "# ===== Block 7 =====\n",
    "import time\n",
    "\n",
    "# Compare models: performance metrics and training time\n",
    "def compare_models(cnn_metrics, tl_metrics, cnn_time, tl_time):\n",
    "    # Unpack metrics\n",
    "    cnn_test_loss, cnn_test_acc = cnn_metrics\n",
    "    tl_test_loss, tl_test_acc = tl_metrics\n",
    "    \n",
    "    # Create table for metrics comparison\n",
    "    print(\"\\n----- Model Comparison -----\")\n",
    "    print(f\"{'Metric':<20} {'Custom CNN':<15} {'ResNet Transfer Learning':<25}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Test Accuracy (%)':<20} {cnn_test_acc:<15.2f} {tl_test_acc:<25.2f}\")\n",
    "    print(f\"{'Test Loss':<20} {cnn_test_loss:<15.4f} {tl_test_loss:<25.4f}\")\n",
    "    print(f\"{'Training Time (s)':<20} {cnn_time:<15.2f} {tl_time:<25.2f}\")\n",
    "    \n",
    "    # Plot comparison chart\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot 1: Test Accuracy Comparison\n",
    "    plt.subplot(2, 2, 1)\n",
    "    models = ['Custom CNN', 'ResNet TL']\n",
    "    accuracies = [cnn_test_acc, tl_test_acc]\n",
    "    plt.bar(models, accuracies, color=['skyblue', 'orange'])\n",
    "    plt.ylabel('Test Accuracy (%)')\n",
    "    plt.title('Test Accuracy Comparison')\n",
    "    \n",
    "    # Plot 2: Test Loss Comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    losses = [cnn_test_loss, tl_test_loss]\n",
    "    plt.bar(models, losses, color=['skyblue', 'orange'])\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.title('Test Loss Comparison')\n",
    "    \n",
    "    # Plot 3: Training Time Comparison\n",
    "    plt.subplot(2, 2, 3)\n",
    "    times = [cnn_time, tl_time]\n",
    "    plt.bar(models, times, color=['skyblue', 'orange'])\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.title('Training Time Comparison')\n",
    "    \n",
    "    # Plot 4: Final Train vs Validation Accuracy\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Data for the comparison\n",
    "    labels = ['Custom CNN', 'ResNet TL']\n",
    "    train_final = [train_accs[-1], tl_train_accs[-1]]\n",
    "    val_final = [val_accs[-1], tl_val_accs[-1]]\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, train_final, width, label='Train Acc')\n",
    "    plt.bar(x + width/2, val_final, width, label='Val Acc')\n",
    "    \n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Final Train vs Validation Accuracy')\n",
    "    plt.xticks(x, labels)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"model_comparison.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Measure training time for both models (we'll simulate since we already trained)\n",
    "# In real use, you would time each training separately\n",
    "start_time = time.time()\n",
    "cnn_train_time = 3636.58  # Replace with your actual timing or recalculate it\n",
    "tl_train_time = 3126.09   # Replace with your actual timing or recalculate it\n",
    "\n",
    "# Compare both models\n",
    "compare_models(\n",
    "    (cnn_test_loss, cnn_test_acc),\n",
    "    (tl_test_loss, tl_test_acc),\n",
    "    cnn_train_time,\n",
    "    tl_train_time\n",
    ")\n",
    "\n",
    "# Plot combined training and validation curves for both models\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot train and validation loss for both models\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, 'b-', label='CNN Train Loss')\n",
    "plt.plot(val_losses, 'b--', label='CNN Val Loss')\n",
    "plt.plot(tl_train_losses, 'r-', label='ResNet Train Loss')\n",
    "plt.plot(tl_val_losses, 'r--', label='ResNet Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Comparison: CNN vs ResNet Transfer Learning')\n",
    "\n",
    "# Plot train and validation accuracy for both models\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, 'b-', label='CNN Train Acc')\n",
    "plt.plot(val_accs, 'b--', label='CNN Val Acc')\n",
    "plt.plot(tl_train_accs, 'r-', label='ResNet Train Acc')\n",
    "plt.plot(tl_val_accs, 'r--', label='ResNet Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Comparison: CNN vs ResNet Transfer Learning')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"combined_training_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n----- Training Summary -----\")\n",
    "print(f\"Custom CNN:\")\n",
    "print(f\"  - Initial Train Loss: {train_losses[0]:.4f}, Final Train Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  - Initial Train Accuracy: {train_accs[0]:.2f}%, Final Train Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"  - Initial Val Loss: {val_losses[0]:.4f}, Final Val Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"  - Initial Val Accuracy: {val_accs[0]:.2f}%, Final Val Accuracy: {val_accs[-1]:.2f}%\")\n",
    "print(f\"  - Test Accuracy: {cnn_test_acc:.2f}%\")\n",
    "print(f\"  - Signs of Overfitting: {'Yes' if train_accs[-1] - val_accs[-1] > 20 else 'No'}\")\n",
    "\n",
    "print(f\"\\nResNet Transfer Learning:\")\n",
    "print(f\"  - Initial Train Loss: {tl_train_losses[0]:.4f}, Final Train Loss: {tl_train_losses[-1]:.4f}\")\n",
    "print(f\"  - Initial Train Accuracy: {tl_train_accs[0]:.2f}%, Final Train Accuracy: {tl_train_accs[-1]:.2f}%\")\n",
    "print(f\"  - Initial Val Loss: {tl_val_losses[0]:.4f}, Final Val Loss: {tl_val_losses[-1]:.4f}\")\n",
    "print(f\"  - Initial Val Accuracy: {tl_val_accs[0]:.2f}%, Final Val Accuracy: {tl_val_accs[-1]:.2f}%\")\n",
    "print(f\"  - Test Accuracy: {tl_test_acc:.2f}%\")\n",
    "print(f\"  - Signs of Overfitting: {'Yes' if tl_train_accs[-1] - tl_val_accs[-1] > 20 else 'No'}\")\n",
    "# ==================="
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
